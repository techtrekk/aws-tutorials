{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Bedrock Claude 2.1\n",
        "We need to create a client and then body to specifiy parameters."
      ],
      "metadata": {
        "id": "aV6XMhzTfgCq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMGvnKZASs9Q"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import json\n",
        "\n",
        "#client of bedrock services\n",
        "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
        "\n",
        "#prompts and parameters to pass into the models\n",
        "body = json.dumps({\n",
        "    \"prompt\": \"\\n\\nHuman: Explain Cloud Computing for class 8th student. n\\nAssistant:\",\n",
        "    \"max_tokens_to_sample\": 300,\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": 0.9,\n",
        "})\n",
        "\n",
        "\n",
        "modelId = 'anthropic.claude-v2'\n",
        "accept = 'application/json'\n",
        "contentType = 'application/json'\n",
        "\n",
        "response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
        "\n",
        "response_body = json.loads(response.get('body').read())\n",
        "\n",
        "# generated response\n",
        "print(response_body.get('completion'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## llama3 Model"
      ],
      "metadata": {
        "id": "E6KH7IH0gRYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json\n",
        "\n",
        "#client of bedrock services\n",
        "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
        "\n",
        "#prompts and parameters to pass into the model\n",
        "body = json.dumps({\n",
        "    \"prompt\": \"\\n Explain AI for class 8th student. \",\n",
        "    \"max_gen_len\": 512,\n",
        "    \"temperature\": 0.2,\n",
        "    \"top_p\": 0.9,\n",
        "})\n",
        "\n",
        "\n",
        "modelId = 'meta.llama3-8b-instruct-v1:0'\n",
        "accept = 'application/json'\n",
        "contentType = 'application/json'\n",
        "\n",
        "response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
        "\n",
        "response_body = json.loads(response.get('body').read())\n",
        "\n",
        "# generated response\n",
        "print(response_body.get('completion'))"
      ],
      "metadata": {
        "id": "s3Fz0cJ8gmux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Titan Text G1 Express Model"
      ],
      "metadata": {
        "id": "y5J6WpVpgW1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json\n",
        "\n",
        "#client of bedrock services\n",
        "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
        "\n",
        "#prompts and parameters to pass into the model\n",
        "body = json.dumps({\n",
        "    \"inputText\": \"\\n Explain AI for class 8th student. \",\n",
        "    \"textGenerationConfig\": {\n",
        "        \"maxTokenCount\": 512,\n",
        "        \"temperature\": 0.5,\n",
        "    },\n",
        "})\n",
        "\n",
        "\n",
        "modelId = \"amazon.titan-text-express-v1\"\n",
        "accept = \"application/json\"\n",
        "contentType = \"application/json\"\n",
        "\n",
        "response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
        "\n",
        "response_body = json.loads(response[\"body\"].read())\n",
        "\n",
        "# generated response\n",
        "print(response_body[\"results\"][0][\"outputText\"])"
      ],
      "metadata": {
        "id": "buMcv2f4gceR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jurassic 2 Ultra"
      ],
      "metadata": {
        "id": "aWXfWpwqqfwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json\n",
        "\n",
        "#client of bedrock services\n",
        "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
        "\n",
        "jurrasic_ultra_prompt = \"Write a Article India's history from 1900 to 1950.\"\n",
        "body = json.dumps({\n",
        "    \"prompt\": jurrasic_ultra_prompt,\n",
        "    \"maxTokens\":256,\n",
        "    \"temperature\":0, #Temperature controls randomness; higher values increase diversity, lower values boost predictability.\n",
        "})\n",
        "\n",
        "\n",
        "modelId = \"ai21.j2-ultra-v1\"\n",
        "accept = \"*/*\"\n",
        "contentType = \"application/json\"\n",
        "\n",
        "response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
        "\n",
        "response_body = json.loads(response[\"body\"].read())\n",
        "\n",
        "# generated response\n",
        "print(response_body.get('completions'))"
      ],
      "metadata": {
        "id": "ZksGHU5HqhkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}